{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "43e71c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inputs(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    german_stop_words = stopwords.words('german')\n",
    "    english_stop_words = stopwords.words('english')\n",
    "    \n",
    "    news = [\"\".join(text)]\n",
    "    news = pd.DataFrame(news, columns=['content'])\n",
    "    \n",
    "    news['content'] = news['content'].str.split(' ').apply(lambda content:\n",
    "    ' '.join([word for word in content if word not in english_stop_words]))\n",
    "    \n",
    "    news['content'] = news['content'].str.split(' ').apply(lambda content:\n",
    "    ' '.join([word for word in content if word not in german_stop_words]))\n",
    "    \n",
    "    news['content'] = news['content'].replace(r'\\n',' ', regex=True)\n",
    "    \n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d27bdacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_classification(news):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "    \n",
    "    news = news['content']\n",
    "    complete_news = pd.read_csv('complete_news_clean.csv')\n",
    "    \n",
    "    label_converter = {1:'Real', 0:'Fake'}\n",
    "    complete_news = complete_news.replace({'label' : label_converter})\n",
    "    \n",
    "    X = complete_news['content']\n",
    "    y = complete_news['label']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 40)\n",
    "    \n",
    "    tfidf = TfidfVectorizer(max_df = 0.85)\n",
    "    \n",
    "    \n",
    "    tfidf_train = tfidf.fit_transform(X_train.astype('U')) \n",
    "    tfidf_test = tfidf.transform(X_test.astype('U'))\n",
    "    \n",
    "    model = PassiveAggressiveClassifier(max_iter = 150, shuffle = True)\n",
    "    model.fit(tfidf_train,y_train)\n",
    "    \n",
    "    #check your news against the model\n",
    "    \n",
    "    tfidf_test = tfidf.transform(news.astype('U'))\n",
    "    \n",
    "    y_pred = model.predict(tfidf_test)[0]\n",
    "    \n",
    "    \n",
    "    classification = y_pred\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "08b2a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial wrapper to have a separate function to classify seperately from setting up the model\n",
    "# This is merely to refactor the solution in the future and make it a bit more modular\n",
    "# For now this function is not relevant\n",
    "\n",
    "def classify_news(news):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "    \n",
    "    news = news['content']\n",
    "    tfidf, model = setup_baseline_model()\n",
    "    \n",
    "    tfidf_test = tfidf.transform(news.astype('U'))\n",
    "    \n",
    "    y_pred = model.predict(tfidf_test)[0]\n",
    "    \n",
    "    \n",
    "    print(f'Those news look like they are {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially the plan was to have a separate function for csv processing\n",
    "# However this was not very compatible with streamlit, so this remains for other use cases\n",
    "\n",
    "def process_csv(file):\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    german_stop_words = stopwords.words('german')\n",
    "    english_stop_words = stopwords.words('english')\n",
    "    \n",
    "    news = [\"\".join(open(file).readlines())]\n",
    "    news = pd.DataFrame(news, columns=['content'])\n",
    "    \n",
    "    news['content'] = news['content'].str.split(' ').apply(lambda content:\n",
    "    ' '.join([word for word in content if word not in english_stop_words]))\n",
    "    \n",
    "    news['content'] = news['content'].str.split(' ').apply(lambda content:\n",
    "    ' '.join([word for word in content if word not in german_stop_words]))\n",
    "    \n",
    "    news['content'] = news['content'].replace(r'\\n',' ', regex=True)\n",
    "    \n",
    "    return news"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
